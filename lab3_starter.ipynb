{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Physics-Informed Neural Networks (PINNs)\n",
    "## Heat Equation with PyTorch\n",
    "\n",
    "**Name:** _________________________\n",
    "\n",
    "**Date:** _________________________\n",
    "\n",
    "**Lab Partner:** _________________________\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "By completing this lab, you will:\n",
    "- Understand what makes PINNs different from traditional methods\n",
    "- Implement a PINN from scratch using PyTorch\n",
    "- Use automatic differentiation to compute PDE residuals\n",
    "- Train a neural network to solve a time-dependent PDE\n",
    "- Compare PINN solutions to analytical solutions\n",
    "- Gain practical experience for Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Print versions\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(\"✓ All packages loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Understanding the Heat Equation\n",
    "\n",
    "## Problem Setup\n",
    "\n",
    "We'll solve the 1D heat equation:\n",
    "\n",
    "$$\\frac{\\partial u}{\\partial t} = 0.1 \\frac{\\partial^2 u}{\\partial x^2}, \\quad x \\in [0, 1], \\, t \\in [0, 0.5]$$\n",
    "\n",
    "**Initial condition:** $u(x, 0) = \\sin(\\pi x)$\n",
    "\n",
    "**Boundary conditions:** $u(0, t) = 0, \\quad u(1, t) = 0$\n",
    "\n",
    "**Analytical solution:** $u(x, t) = e^{-0.1 \\pi^2 t} \\sin(\\pi x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1: Visualize the Analytical Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "alpha = 0.1      # Thermal diffusivity\n",
    "L = 1.0          # Rod length\n",
    "T_max = 0.5      # Maximum time\n",
    "\n",
    "# Create spatial grid\n",
    "x = np.linspace(0, L, 100)\n",
    "\n",
    "# Function to compute analytical solution\n",
    "def analytical_solution(x, t, alpha):\n",
    "    \"\"\"\n",
    "    Analytical solution to heat equation\n",
    "    \n",
    "    Args:\n",
    "        x: Position (array or scalar)\n",
    "        t: Time (scalar)\n",
    "        alpha: Thermal diffusivity\n",
    "    \n",
    "    Returns:\n",
    "        Temperature u(x,t)\n",
    "    \"\"\"\n",
    "    return np.exp(-alpha * np.pi**2 * t) * np.sin(np.pi * x)\n",
    "\n",
    "# Plot at different times\n",
    "times = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "colors = plt.cm.hot(np.linspace(0.3, 1, len(times)))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for t, color in zip(times, colors):\n",
    "    u = analytical_solution(x, t, alpha)\n",
    "    plt.plot(x, u, label=f't = {t:.1f}s', color=color, linewidth=2)\n",
    "\n",
    "plt.xlabel('Position x (m)', fontsize=12)\n",
    "plt.ylabel('Temperature u(x,t) (°C)', fontsize=12)\n",
    "plt.title('Analytical Solution: Heat Diffusion in a Rod', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytical_solution.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2: Understanding the Physics\n",
    "\n",
    "**Discuss with your lab partner and answer:**\n",
    "\n",
    "1. **How does the maximum temperature change over time?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "2. **Why do the ends stay at zero?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "3. **What happens as t → ∞?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "4. **What would change if we increased α?**\n",
    "   - Answer: _______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Building a PINN from Scratch\n",
    "\n",
    "## The PINN Recipe (3 Steps)\n",
    "\n",
    "1. **Represent solution as neural network:** $u(x,t) \\approx u_\\theta(x,t)$\n",
    "2. **Define loss function:** $\\mathcal{L} = \\|\\text{PDE residual}\\|^2 + \\|\\text{BC violation}\\|^2 + \\|\\text{IC violation}\\|^2$\n",
    "3. **Train network to minimize loss:** $\\theta_{\\text{new}} = \\theta_{\\text{old}} - \\eta \\nabla_\\theta \\mathcal{L}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeatPINN(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network to approximate u(x, t)\n",
    "    \n",
    "    Architecture:\n",
    "        Input:  [x, t] (2D)\n",
    "        Hidden: 4 layers × 20 neurons each\n",
    "        Output: u (1D)\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_layers=4, neurons_per_layer=20):\n",
    "        super(HeatPINN, self).__init__()\n",
    "        \n",
    "        # Build layers list\n",
    "        layers = []\n",
    "        \n",
    "        # Input layer: 2 inputs (x, t) → neurons_per_layer\n",
    "        layers.append(nn.Linear(2, neurons_per_layer))\n",
    "        layers.append(nn.Tanh())\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(hidden_layers - 1):\n",
    "            layers.append(nn.Linear(neurons_per_layer, neurons_per_layer))\n",
    "            layers.append(nn.Tanh())\n",
    "        \n",
    "        # Output layer: neurons_per_layer → 1 output (u)\n",
    "        layers.append(nn.Linear(neurons_per_layer, 1))\n",
    "        \n",
    "        # Combine into sequential network\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        Forward pass through network\n",
    "        \n",
    "        Args:\n",
    "            x: Spatial coordinate (N × 1 tensor)\n",
    "            t: Time coordinate (N × 1 tensor)\n",
    "        \n",
    "        Returns:\n",
    "            u: Temperature predictions (N × 1 tensor)\n",
    "        \"\"\"\n",
    "        # Concatenate x and t into single input\n",
    "        inputs = torch.cat([x, t], dim=1)  # Shape: (N, 2)\n",
    "        return self.network(inputs)\n",
    "\n",
    "# Create model\n",
    "model = HeatPINN(hidden_layers=4, neurons_per_layer=20)\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"✓ Model created with {num_params} trainable parameters\")\n",
    "\n",
    "# Test forward pass\n",
    "x_test = torch.tensor([[0.5]])  # Middle of rod\n",
    "t_test = torch.tensor([[0.0]])  # At t=0\n",
    "u_test = model(x_test, t_test)\n",
    "print(f\"✓ Forward pass works! u(0.5, 0) = {u_test.item():.4f} (random initialization)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1: Understanding the Architecture\n",
    "\n",
    "1. **How many inputs does the network have? Why?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "2. **How many outputs? Why?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "3. **Why do we use Tanh activation instead of ReLU?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "4. **What would happen if we used only 1 hidden layer?**\n",
    "   - Answer: _______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compute PDE Residual (The Magic!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pde_residual(model, x, t, alpha):\n",
    "    \"\"\"\n",
    "    Compute PDE residual using automatic differentiation\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network\n",
    "        x: Spatial points (N × 1 tensor, requires_grad=True)\n",
    "        t: Time points (N × 1 tensor, requires_grad=True)\n",
    "        alpha: Thermal diffusivity\n",
    "    \n",
    "    Returns:\n",
    "        residual: du/dt - alpha * d²u/dx² (N × 1 tensor)\n",
    "    \"\"\"\n",
    "    # Ensure gradients are enabled\n",
    "    x.requires_grad_(True)\n",
    "    t.requires_grad_(True)\n",
    "    \n",
    "    # Forward pass: compute u(x,t)\n",
    "    u = model(x, t)\n",
    "    \n",
    "    # First derivatives using automatic differentiation\n",
    "    u_t = torch.autograd.grad(\n",
    "        outputs=u,\n",
    "        inputs=t,\n",
    "        grad_outputs=torch.ones_like(u),\n",
    "        create_graph=True,      # Keep graph for higher derivatives\n",
    "        retain_graph=True       # Don't destroy graph\n",
    "    )[0]\n",
    "    \n",
    "    u_x = torch.autograd.grad(\n",
    "        outputs=u,\n",
    "        inputs=x,\n",
    "        grad_outputs=torch.ones_like(u),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    \n",
    "    # Second derivative: d²u/dx²\n",
    "    u_xx = torch.autograd.grad(\n",
    "        outputs=u_x,\n",
    "        inputs=x,\n",
    "        grad_outputs=torch.ones_like(u_x),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    \n",
    "    # Compute residual: du/dt - alpha * d²u/dx²\n",
    "    residual = u_t - alpha * u_xx\n",
    "    \n",
    "    return residual\n",
    "\n",
    "# Test it!\n",
    "x_test = torch.tensor([[0.5]], requires_grad=True)\n",
    "t_test = torch.tensor([[0.1]], requires_grad=True)\n",
    "\n",
    "residual = compute_pde_residual(model, x_test, t_test, alpha=0.1)\n",
    "print(f\"✓ PDE residual at (x=0.5, t=0.1): {residual.item():.6f}\")\n",
    "print(\"  (Should be close to 0 after training!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2: Understanding Automatic Differentiation\n",
    "\n",
    "1. **Why do we need `create_graph=True`?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "2. **What happens if we forget it when computing u_xx?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "3. **What does `grad_outputs=torch.ones_like(u)` do?**\n",
    "   - Answer: _______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Training Data (Collocation Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(n_domain=1000, n_boundary=100, n_initial=100):\n",
    "    \"\"\"\n",
    "    Create collocation points for training\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with 'domain', 'boundary', 'initial' point sets\n",
    "    \"\"\"\n",
    "    # Domain points: random in [0,1] × [0,0.5]\n",
    "    x_domain = torch.rand(n_domain, 1)\n",
    "    t_domain = torch.rand(n_domain, 1) * 0.5\n",
    "    \n",
    "    # Boundary points: x=0 and x=1 for various t\n",
    "    t_boundary = torch.rand(n_boundary, 1) * 0.5\n",
    "    \n",
    "    # Left boundary (x=0)\n",
    "    x_boundary_left = torch.zeros(n_boundary // 2, 1)\n",
    "    t_boundary_left = t_boundary[:n_boundary // 2]\n",
    "    \n",
    "    # Right boundary (x=1)\n",
    "    x_boundary_right = torch.ones(n_boundary // 2, 1)\n",
    "    t_boundary_right = t_boundary[n_boundary // 2:]\n",
    "    \n",
    "    # Combine boundaries\n",
    "    x_boundary = torch.cat([x_boundary_left, x_boundary_right])\n",
    "    t_boundary = torch.cat([t_boundary_left, t_boundary_right])\n",
    "    \n",
    "    # Initial condition points: t=0 for various x\n",
    "    x_initial = torch.rand(n_initial, 1)\n",
    "    t_initial = torch.zeros(n_initial, 1)\n",
    "    \n",
    "    return {\n",
    "        'domain': (x_domain, t_domain),\n",
    "        'boundary': (x_boundary, t_boundary),\n",
    "        'initial': (x_initial, t_initial)\n",
    "    }\n",
    "\n",
    "# Create data\n",
    "data = create_training_data(n_domain=1000, n_boundary=100, n_initial=100)\n",
    "\n",
    "print(f\"✓ Created training data:\")\n",
    "print(f\"  Domain points:   {data['domain'][0].shape[0]}\")\n",
    "print(f\"  Boundary points: {data['boundary'][0].shape[0]}\")\n",
    "print(f\"  Initial points:  {data['initial'][0].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize collocation points\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(data['domain'][0].numpy(), data['domain'][1].numpy(), \n",
    "           s=2, alpha=0.3, c='blue', label='Domain (PDE enforced)')\n",
    "plt.scatter(data['boundary'][0].numpy(), data['boundary'][1].numpy(), \n",
    "           s=20, c='red', marker='s', label='Boundary (BC enforced)')\n",
    "plt.scatter(data['initial'][0].numpy(), data['initial'][1].numpy(), \n",
    "           s=20, c='green', marker='^', label='Initial (IC enforced)')\n",
    "\n",
    "plt.xlabel('Position x (m)', fontsize=12)\n",
    "plt.ylabel('Time t (s)', fontsize=12)\n",
    "plt.title('Collocation Points for PINN Training', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(-0.05, 0.55)\n",
    "plt.tight_layout()\n",
    "plt.savefig('collocation_points.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, data, alpha):\n",
    "    \"\"\"\n",
    "    Compute total loss = PDE loss + BC loss + IC loss\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network\n",
    "        data: Dictionary with training data\n",
    "        alpha: Thermal diffusivity\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (total_loss, pde_loss, bc_loss, ic_loss)\n",
    "    \"\"\"\n",
    "    x_domain, t_domain = data['domain']\n",
    "    x_boundary, t_boundary = data['boundary']\n",
    "    x_initial, t_initial = data['initial']\n",
    "    \n",
    "    # 1. PDE Loss: Enforce heat equation in interior\n",
    "    residual = compute_pde_residual(model, x_domain, t_domain, alpha)\n",
    "    loss_pde = torch.mean(residual**2)\n",
    "    \n",
    "    # 2. Boundary Condition Loss: u(0,t) = u(1,t) = 0\n",
    "    u_boundary = model(x_boundary, t_boundary)\n",
    "    loss_bc = torch.mean(u_boundary**2)\n",
    "    \n",
    "    # 3. Initial Condition Loss: u(x,0) = sin(πx)\n",
    "    u_initial = model(x_initial, t_initial)\n",
    "    u_initial_true = torch.sin(np.pi * x_initial)\n",
    "    loss_ic = torch.mean((u_initial - u_initial_true)**2)\n",
    "    \n",
    "    # Total loss (could add weights here)\n",
    "    loss_total = loss_pde + loss_bc + loss_ic\n",
    "    \n",
    "    return loss_total, loss_pde, loss_bc, loss_ic\n",
    "\n",
    "# Test loss computation\n",
    "loss_total, loss_pde, loss_bc, loss_ic = compute_loss(model, data, alpha=0.1)\n",
    "\n",
    "print(f\"✓ Loss computation works!\")\n",
    "print(f\"  Initial losses (before training):\")\n",
    "print(f\"    Total:    {loss_total.item():.6f}\")\n",
    "print(f\"    PDE:      {loss_pde.item():.6f}\")\n",
    "print(f\"    BC:       {loss_bc.item():.6f}\")\n",
    "print(f\"    IC:       {loss_ic.item():.6f}\")\n",
    "print(f\"\\n  Goal: All losses → 0 after training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.3: Loss Function Analysis\n",
    "\n",
    "1. **Why do we square the residuals before taking the mean?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "2. **What would happen if we removed the IC loss?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "3. **Should all three loss terms have equal weight? Why or why not?**\n",
    "   - Answer: _______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pinn(model, data, alpha, epochs=5000, lr=0.001):\n",
    "    \"\"\"\n",
    "    Train the PINN by minimizing loss\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network\n",
    "        data: Training data dictionary\n",
    "        alpha: Thermal diffusivity\n",
    "        epochs: Number of training iterations\n",
    "        lr: Learning rate\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with loss history\n",
    "    \"\"\"\n",
    "    # Set up optimizer (Adam = fancy gradient descent)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Storage for loss history\n",
    "    history = {'total': [], 'pde': [], 'bc': [], 'ic': []}\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    print(f\"{'Epoch':>7} | {'Total Loss':>12} | {'PDE Loss':>12} | {'BC Loss':>12} | {'IC Loss':>12}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute loss\n",
    "        loss_total, loss_pde, loss_bc, loss_ic = compute_loss(model, data, alpha)\n",
    "        \n",
    "        # Backpropagation: compute gradients\n",
    "        loss_total.backward()\n",
    "        \n",
    "        # Update parameters: θ_new = θ_old - lr * ∇L\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Record history\n",
    "        history['total'].append(loss_total.item())\n",
    "        history['pde'].append(loss_pde.item())\n",
    "        history['bc'].append(loss_bc.item())\n",
    "        history['ic'].append(loss_ic.item())\n",
    "        \n",
    "        # Print progress every 500 epochs\n",
    "        if epoch % 500 == 0 or epoch == epochs - 1:\n",
    "            print(f\"{epoch:7d} | {loss_total.item():12.6e} | \"\n",
    "                  f\"{loss_pde.item():12.6e} | \"\n",
    "                  f\"{loss_bc.item():12.6e} | \"\n",
    "                  f\"{loss_ic.item():12.6e}\")\n",
    "    \n",
    "    print(\"\\n✓ Training complete!\")\n",
    "    return history\n",
    "\n",
    "# Train the model!\n",
    "history = train_pinn(model, data, alpha=0.1, epochs=5000, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Total loss (log scale)\n",
    "axes[0].semilogy(history['total'], 'b-', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Total Loss (log scale)', fontsize=12)\n",
    "axes[0].set_title('Total Loss During Training', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Individual components\n",
    "axes[1].semilogy(history['pde'], label='PDE Loss', linewidth=2)\n",
    "axes[1].semilogy(history['bc'], label='BC Loss', linewidth=2)\n",
    "axes[1].semilogy(history['ic'], label='IC Loss', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss (log scale)', fontsize=12)\n",
    "axes[1].set_title('Loss Components', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.4: Training Dynamics\n",
    "\n",
    "1. **Which loss component decreases fastest? Why?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "2. **Does the total loss reach exactly zero? Should it?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "3. **What would you try if training didn't converge?**\n",
    "   - Answer: _______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Predictions on a Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pinn(model, nx=100, nt=100):\n",
    "    \"\"\"\n",
    "    Evaluate PINN on a regular grid for visualization\n",
    "    \n",
    "    Args:\n",
    "        model: Trained neural network\n",
    "        nx: Number of spatial points\n",
    "        nt: Number of time points\n",
    "    \n",
    "    Returns:\n",
    "        X, T, u_pred: Meshgrids and predictions\n",
    "    \"\"\"\n",
    "    # Create test grid\n",
    "    x = torch.linspace(0, 1, nx).reshape(-1, 1)\n",
    "    t = torch.linspace(0, 0.5, nt).reshape(-1, 1)\n",
    "    \n",
    "    # Create meshgrid\n",
    "    X, T = torch.meshgrid(x.squeeze(), t.squeeze(), indexing='ij')\n",
    "    x_flat = X.reshape(-1, 1)\n",
    "    t_flat = T.reshape(-1, 1)\n",
    "    \n",
    "    # Predictions (no gradients needed)\n",
    "    with torch.no_grad():\n",
    "        u_pred = model(x_flat, t_flat).reshape(X.shape)\n",
    "    \n",
    "    return X.numpy(), T.numpy(), u_pred.numpy()\n",
    "\n",
    "# Evaluate PINN\n",
    "print(\"Evaluating PINN on test grid...\")\n",
    "X, T, u_pred = evaluate_pinn(model, nx=100, nt=100)\n",
    "\n",
    "# Compute analytical solution\n",
    "u_true = analytical_solution(X, T, alpha=0.1)\n",
    "\n",
    "# Compute error\n",
    "error = np.abs(u_pred - u_true)\n",
    "\n",
    "print(f\"✓ Evaluation complete!\")\n",
    "print(f\"  Grid size: {X.shape}\")\n",
    "print(f\"  Total test points: {X.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Visualize Results (The Moment of Truth!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# PINN solution\n",
    "im1 = axes[0].contourf(X, T, u_pred, levels=50, cmap='hot')\n",
    "axes[0].set_xlabel('Position x (m)', fontsize=11)\n",
    "axes[0].set_ylabel('Time t (s)', fontsize=11)\n",
    "axes[0].set_title('PINN Solution', fontsize=13, fontweight='bold')\n",
    "cbar1 = plt.colorbar(im1, ax=axes[0])\n",
    "cbar1.set_label('Temperature (°C)', fontsize=10)\n",
    "\n",
    "# Analytical solution\n",
    "im2 = axes[1].contourf(X, T, u_true, levels=50, cmap='hot')\n",
    "axes[1].set_xlabel('Position x (m)', fontsize=11)\n",
    "axes[1].set_ylabel('Time t (s)', fontsize=11)\n",
    "axes[1].set_title('Analytical Solution', fontsize=13, fontweight='bold')\n",
    "cbar2 = plt.colorbar(im2, ax=axes[1])\n",
    "cbar2.set_label('Temperature (°C)', fontsize=10)\n",
    "\n",
    "# Absolute error\n",
    "im3 = axes[2].contourf(X, T, error, levels=50, cmap='viridis')\n",
    "axes[2].set_xlabel('Position x (m)', fontsize=11)\n",
    "axes[2].set_ylabel('Time t (s)', fontsize=11)\n",
    "axes[2].set_title('Absolute Error', fontsize=13, fontweight='bold')\n",
    "cbar3 = plt.colorbar(im3, ax=axes[2])\n",
    "cbar3.set_label('|u_PINN - u_true| (°C)', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('solution_comparison.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Print error statistics\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"ERROR STATISTICS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"  Max error:        {np.max(error):.6f}\")\n",
    "print(f\"  Mean error:       {np.mean(error):.6f}\")\n",
    "print(f\"  L2 error:         {np.sqrt(np.mean(error**2)):.6f}\")\n",
    "print(f\"  Relative L2 (%):  {100 * np.linalg.norm(error) / np.linalg.norm(u_true):.2f}%\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Temporal Snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot solution profiles at different times\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "times = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "colors = plt.cm.hot(np.linspace(0.3, 1, len(times)))\n",
    "x_plot = X[:, 0]\n",
    "\n",
    "for i, (t_val, color) in enumerate(zip(times, colors)):\n",
    "    # Find closest time index\n",
    "    t_idx = np.argmin(np.abs(T[0, :] - t_val))\n",
    "    \n",
    "    # Plot PINN (solid line with markers)\n",
    "    ax.plot(x_plot, u_pred[:, t_idx], 'o-', \n",
    "           label=f't={t_val:.1f}s (PINN)', \n",
    "           color=color, markersize=5, linewidth=2.5, alpha=0.9)\n",
    "    \n",
    "    # Plot analytical (dashed line)\n",
    "    ax.plot(x_plot, u_true[:, t_idx], '--', \n",
    "           color=color, linewidth=2, alpha=0.6)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.lines import Line2D\n",
    "custom_lines = [\n",
    "    Line2D([0], [0], color='black', linewidth=2.5, linestyle='-'),\n",
    "    Line2D([0], [0], color='black', linewidth=2, linestyle='--')\n",
    "]\n",
    "legend1 = ax.legend(custom_lines, ['PINN', 'Analytical'], \n",
    "                   loc='upper right', fontsize=11, title='Method')\n",
    "\n",
    "ax.set_xlabel('Position x (m)', fontsize=13)\n",
    "ax.set_ylabel('Temperature u(x,t) (°C)', fontsize=13)\n",
    "ax.set_title('Temperature Evolution: Comparing PINN vs Analytical', \n",
    "            fontsize=15, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(-0.02, 1.02)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('temporal_snapshots.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.1: Results Analysis\n",
    "\n",
    "1. **Where is the error largest? Why might this be?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "2. **How does the relative L2 error compare to typical finite difference accuracy?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "3. **Does the PINN respect physics at t=0.5? Does it look reasonable?**\n",
    "   - Answer: _______________________________________________\n",
    "\n",
    "4. **What do you think would happen if we trained for 50,000 epochs instead of 5,000?**\n",
    "   - Answer: _______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Experimentation\n",
    "\n",
    "Try modifying the PINN to see what happens! **This is the fun part!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.1: Architecture Exploration\n",
    "\n",
    "Change the network architecture and retrain. Try at least 2 configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration 1: Fewer layers\n",
    "# TODO: Implement and train model_small\n",
    "# model_small = HeatPINN(hidden_layers=2, neurons_per_layer=20)\n",
    "# history_small = train_pinn(model_small, data, alpha=0.1, epochs=5000, lr=0.001)\n",
    "# Evaluate and compute error..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration 2: More neurons\n",
    "# TODO: Implement and train model_wide\n",
    "# model_wide = HeatPINN(hidden_layers=4, neurons_per_layer=50)\n",
    "# history_wide = train_pinn(model_wide, data, alpha=0.1, epochs=5000, lr=0.001)\n",
    "# Evaluate and compute error..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record your results:**\n",
    "\n",
    "Original (4 layers × 20 neurons, Tanh):\n",
    "- Training time: _____ seconds\n",
    "- Final total loss: _____\n",
    "- Max error: _____\n",
    "- Relative L2: _____\n",
    "\n",
    "Configuration 1: [your description]\n",
    "- Training time: _____ seconds\n",
    "- Final total loss: _____\n",
    "- Max error: _____\n",
    "- Relative L2: _____\n",
    "\n",
    "Configuration 2: [your description]\n",
    "- Training time: _____ seconds\n",
    "- Final total loss: _____\n",
    "- Max error: _____\n",
    "- Relative L2: _____\n",
    "\n",
    "**Discussion:** Which architecture worked best? Why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.2: Collocation Point Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try different numbers of collocation points\n",
    "# Fewer points:\n",
    "# data_sparse = create_training_data(n_domain=500, n_boundary=50, n_initial=50)\n",
    "# history_sparse = train_pinn(model, data_sparse, alpha=0.1, epochs=5000, lr=0.001)\n",
    "\n",
    "# More points:\n",
    "# data_dense = create_training_data(n_domain=2000, n_boundary=200, n_initial=200)\n",
    "# history_dense = train_pinn(model, data_dense, alpha=0.1, epochs=5000, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record your results:**\n",
    "\n",
    "Fewer points (500/50/50):\n",
    "- Training time: _____ seconds\n",
    "- Final total loss: _____\n",
    "- Max error: _____\n",
    "\n",
    "Original (1000/100/100):\n",
    "- Training time: _____ seconds\n",
    "- Final total loss: _____\n",
    "- Max error: _____\n",
    "\n",
    "More points (2000/200/200):\n",
    "- Training time: _____ seconds\n",
    "- Final total loss: _____\n",
    "- Max error: _____\n",
    "\n",
    "**Discussion:** Is there a point of diminishing returns? What's the sweet spot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Reflection and Connection to Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.1: Project Planning\n",
    "\n",
    "Based on this lab experience, answer these questions:\n",
    "\n",
    "**1. Which PDE are you leaning toward for Project 1?**\n",
    "- [ ] Wave Equation\n",
    "- [ ] Burgers' Equation\n",
    "- [ ] Laplace/Poisson Equation\n",
    "\n",
    "Why this choice?\n",
    "\n",
    "_________________________________________________________________________\n",
    "\n",
    "_________________________________________________________________________\n",
    "\n",
    "**2. What challenges do you anticipate in implementing your chosen PDE?**\n",
    "\n",
    "_________________________________________________________________________\n",
    "\n",
    "_________________________________________________________________________\n",
    "\n",
    "**3. From today's lab, what would you do differently in your project?**\n",
    "\n",
    "_________________________________________________________________________\n",
    "\n",
    "_________________________________________________________________________\n",
    "\n",
    "**4. What surprised you most about PINNs?**\n",
    "\n",
    "_________________________________________________________________________\n",
    "\n",
    "_________________________________________________________________________\n",
    "\n",
    "**5. When would you choose PINN vs traditional finite difference?**\n",
    "\n",
    "Use PINN when:\n",
    "\n",
    "_________________________________________________________________________\n",
    "\n",
    "Use finite difference when:\n",
    "\n",
    "_________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Submission Checklist\n",
    "\n",
    "Before submitting, make sure you have:\n",
    "\n",
    "- [ ] Completed all exercises with answers filled in\n",
    "- [ ] All code cells run without errors\n",
    "- [ ] All five figures saved:\n",
    "  - [ ] `analytical_solution.png`\n",
    "  - [ ] `collocation_points.png`\n",
    "  - [ ] `training_history.png`\n",
    "  - [ ] `solution_comparison.png`\n",
    "  - [ ] `temporal_snapshots.png`\n",
    "- [ ] Completed Part 5 reflection questions\n",
    "- [ ] Restarted kernel and ran all cells (Kernel → Restart & Run All)\n",
    "\n",
    "**Submit via Canvas:**\n",
    "1. This notebook (renamed to `lab4_[YourName].ipynb`)\n",
    "2. All five PNG figures\n",
    "3. Brief reflection (1 paragraph) in a separate document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Resources\n",
    "\n",
    "**PyTorch Tutorials:**\n",
    "- Autograd tutorial: https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
    "- Neural networks: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "\n",
    "**PINN Papers:**\n",
    "- Original paper: Raissi et al., *J. Comput. Phys.* 378 (2019)\n",
    "  - https://www.sciencedirect.com/science/article/pii/S0021999118307125\n",
    "\n",
    "**DeepXDE:**\n",
    "- Documentation: https://deepxde.readthedocs.io/\n",
    "- Examples: https://github.com/lululxvi/deepxde/tree/master/examples\n",
    "\n",
    "**Office Hours:**\n",
    "- Tuesdays 2-4pm\n",
    "- Thursdays 10-12pm\n",
    "- Or by appointment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
